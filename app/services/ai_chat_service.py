"""
AI ì±„íŒ… ì„œë¹„ìŠ¤

ì‹¤ì œ AI ê¸°ë°˜ ì±„íŒ… ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import asyncio
from typing import List, Tuple, Optional, Dict, Any
from langchain.schema import HumanMessage, AIMessage, SystemMessage
import structlog
from datetime import datetime

from app.core.langchain_config import langchain_manager, PromptTemplates, ChatConfiguration
from app.config.settings import settings
from app.utils.openai_utils import validator, usage_tracker, get_token_counter

logger = structlog.get_logger()


class AIChatService:
    """AI ì±„íŒ… ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.langchain_manager = langchain_manager
        self.is_available = self._check_availability()
        self.conversation_count = 0
    
    def _check_availability(self) -> bool:
        """AI ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if not self.langchain_manager:
            logger.warning("LangChain ê´€ë¦¬ìê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
            return False
        
        if not settings.openai_api_key or settings.openai_api_key == "your-openai-api-key-here":
            logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return False
        
        return True
    
    async def send_message(self, user_message: str, conversation_history: List[Tuple[str, str]] = None) -> Tuple[str, bool]:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ AI ì‘ë‹µ ìƒì„±
        
        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” ê¸°ë¡ (ì„ íƒì‚¬í•­)
        
        Returns:
            Tuple[ì‘ë‹µ ë©”ì‹œì§€, ì„±ê³µ ì—¬ë¶€]
        """
        if not self.is_available:
            return self._get_fallback_response(user_message), False
        
        try:
            # ëŒ€í™” íƒ€ì… ê°ì§€
            conversation_type = self._detect_conversation_type(user_message)
            logger.info("ëŒ€í™” íƒ€ì… ê°ì§€", type=conversation_type, message=user_message)
            
            # ì„¤ì • ë¡œë“œ
            config = ChatConfiguration.get_config(conversation_type)
            
            # LLM ì„¤ì • ì—…ë°ì´íŠ¸
            llm = self.langchain_manager.get_llm()
            llm.temperature = config["temperature"]
            llm.max_tokens = config["max_tokens"]
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = self._build_messages(user_message, conversation_type, conversation_history)
            
            # AI ì‘ë‹µ ìƒì„±
            response = await self._generate_response(llm, messages)
            
            # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
            self._save_to_memory(user_message, response)
            
            # ì‘ë‹µ í›„ì²˜ë¦¬
            formatted_response = self._format_response(response, conversation_type)
            
            self.conversation_count += 1
            logger.info("AI ì‘ë‹µ ìƒì„± ì™„ë£Œ", 
                       conversation_count=self.conversation_count,
                       response_length=len(formatted_response))
            
            return formatted_response, True
            
        except Exception as e:
            logger.error("AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨", error=str(e))
            return self._get_error_response(str(e)), False
    
    def _detect_conversation_type(self, message: str) -> str:
        """ëŒ€í™” íƒ€ì… ê°ì§€"""
        message_lower = message.lower()
        
        # SQL ê´€ë ¨ í‚¤ì›Œë“œ
        sql_keywords = [
            'sql', 'select', 'query', 'ì¿¼ë¦¬', 'ì¡°íšŒ', 'database', 'ë°ì´í„°ë² ì´ìŠ¤',
            'table', 'í…Œì´ë¸”', 'join', 'where', 'group by', 'order by'
        ]
        
        # ë°ì´í„° ë¶„ì„ í‚¤ì›Œë“œ
        analysis_keywords = [
            'ë¶„ì„', 'í†µê³„', 'í‰ê· ', 'í•©ê³„', 'ìµœëŒ€', 'ìµœì†Œ', 'íŠ¸ë Œë“œ', 'íŒ¨í„´',
            'ìƒê´€ê´€ê³„', 'ì˜ˆì¸¡', 'ëª¨ë¸ë§', 'ì¸ì‚¬ì´íŠ¸', 'ëŒ€ì‹œë³´ë“œ'
        ]
        
        # Excel/íŒŒì¼ ê´€ë ¨ í‚¤ì›Œë“œ
        excel_keywords = [
            'excel', 'csv', 'ì—‘ì…€', 'íŒŒì¼', 'ìŠ¤í”„ë ˆë“œì‹œíŠ¸', 'ì—…ë¡œë“œ',
            'ë°ì´í„° íŒŒì¼', 'ì›Œí¬ë¶', 'ì‹œíŠ¸'
        ]
        
        if any(keyword in message_lower for keyword in sql_keywords):
            return "sql"
        elif any(keyword in message_lower for keyword in excel_keywords):
            return "excel"
        elif any(keyword in message_lower for keyword in analysis_keywords):
            return "data_analysis"
        else:
            return "general"
    
    def _build_messages(self, user_message: str, conversation_type: str, 
                       conversation_history: List[Tuple[str, str]] = None) -> List:
        """ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±"""
        messages = []
        
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
        messages.append(PromptTemplates.get_system_message())
        
        # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
        if conversation_history:
            recent_history = conversation_history[-5:]
            for user_msg, ai_msg in recent_history:
                messages.append(HumanMessage(content=user_msg))
                if ai_msg:
                    messages.append(AIMessage(content=ai_msg))
        
        # íƒ€ì…ë³„ ì»¨í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
        context_message = self._get_context_message(conversation_type, user_message)
        if context_message:
            messages.append(HumanMessage(content=context_message))
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append(HumanMessage(content=user_message))
        
        return messages
    
    def _get_context_message(self, conversation_type: str, user_message: str) -> Optional[str]:
        """íƒ€ì…ë³„ ì»¨í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ìƒì„±"""
        if conversation_type == "data_analysis":
            return PromptTemplates.format_data_analysis_prompt(
                question=user_message,
                context="Week 2 ê°œë°œ ë‹¨ê³„ - ê¸°ë³¸ AI ì±„íŒ… êµ¬í˜„ ì¤‘"
            )
        elif conversation_type == "sql":
            return PromptTemplates.format_sql_prompt(
                question=user_message,
                schema="ì•„ì§ ìŠ¤í‚¤ë§ˆ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤ (Week 3ì—ì„œ êµ¬í˜„ ì˜ˆì •)"
            )
        elif conversation_type == "excel":
            return PromptTemplates.format_excel_prompt(
                question=user_message,
                file_info="ì•„ì§ íŒŒì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤ (Week 4ì—ì„œ êµ¬í˜„ ì˜ˆì •)"
            )
        return None
    
    async def _generate_response(self, llm, messages: List) -> str:
        """AI ì‘ë‹µ ìƒì„±"""
        try:
            # í† í° ìˆ˜ ê³„ì‚° (ìš”ì²­ ì „)
            token_counter = get_token_counter(settings.openai_model)
            
            # ë©”ì‹œì§€ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ í† í° ê³„ì‚°
            message_texts = []
            for msg in messages:
                if hasattr(msg, 'content'):
                    message_texts.append(msg.content)
            
            input_tokens = sum(token_counter.count_tokens(text) for text in message_texts)
            
            # í† í° ì œí•œ í™•ì¸
            from app.utils.openai_utils import ModelInfo
            is_valid, token_message = ModelInfo.validate_token_limit(settings.openai_model, input_tokens)
            
            if not is_valid:
                raise Exception(token_message)
            
            # ë¹„ë™ê¸° í˜¸ì¶œ
            response = await asyncio.wait_for(
                asyncio.to_thread(llm.invoke, messages),
                timeout=ChatConfiguration.TIMEOUT_SECONDS
            )
            
            if response and hasattr(response, 'content'):
                # ì‘ë‹µ í† í° ìˆ˜ ê³„ì‚° ë° ì‚¬ìš©ëŸ‰ ì¶”ì 
                output_tokens = token_counter.count_tokens(response.content)
                usage_tracker.track_usage(settings.openai_model, input_tokens, output_tokens)
                
                logger.info("AI ì‘ë‹µ ìƒì„± ì™„ë£Œ",
                           input_tokens=input_tokens,
                           output_tokens=output_tokens,
                           model=settings.openai_model)
                
                return response.content
            else:
                raise ValueError("ë¹ˆ ì‘ë‹µ ë°›ìŒ")
                
        except asyncio.TimeoutError:
            raise Exception("ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
        except Exception as e:
            raise Exception(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
    
    def _save_to_memory(self, user_message: str, ai_response: str):
        """ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥"""
        if self.langchain_manager and self.langchain_manager.memory:
            self.langchain_manager.add_user_message(user_message)
            self.langchain_manager.add_ai_message(ai_response)
    
    def _format_response(self, response: str, conversation_type: str) -> str:
        """ì‘ë‹µ í¬ë§·íŒ…"""
        # ê¸°ë³¸ í¬ë§·íŒ…
        formatted = response.strip()
        
        # íƒ€ì…ë³„ í›„ì²˜ë¦¬
        if conversation_type == "sql":
            # SQL ì‘ë‹µì— ì£¼ì˜ì‚¬í•­ ì¶”ê°€
            if "SELECT" in formatted.upper() or "sql" in formatted.lower():
                formatted += "\n\nğŸ’¡ **ì°¸ê³ **: ì‹¤ì œ SQL ì‹¤í–‰ì€ Week 3ì—ì„œ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤."
        
        elif conversation_type == "excel":
            # Excel ì‘ë‹µì— ì•ˆë‚´ ì¶”ê°€
            formatted += "\n\nğŸ“ **ì°¸ê³ **: ì‹¤ì œ íŒŒì¼ ë¶„ì„ ê¸°ëŠ¥ì€ Week 4ì—ì„œ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤."
        
        elif conversation_type == "data_analysis":
            # ë°ì´í„° ë¶„ì„ ì‘ë‹µì— ì°¨íŠ¸ ì•ˆë‚´ ì¶”ê°€
            formatted += "\n\nğŸ“Š **ì°¸ê³ **: ë°ì´í„° ì‹œê°í™” ê¸°ëŠ¥ì€ Week 5ì—ì„œ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤."
        
        # ê°œë°œ ìƒíƒœ ì •ë³´ ì¶”ê°€ (ê°€ë”ì”©)
        if self.conversation_count % 5 == 0:
            formatted += f"\n\nğŸš€ **ê°œë°œ í˜„í™©**: Week 2 - AI ì±„íŒ… ê¸°ëŠ¥ êµ¬í˜„ ì¤‘ (ëŒ€í™” {self.conversation_count}íšŒ)"
        
        return formatted
    
    def _get_fallback_response(self, user_message: str) -> str:
        """AI ì„œë¹„ìŠ¤ ë¶ˆê°€ëŠ¥ì‹œ ëŒ€ì²´ ì‘ë‹µ"""
        responses = [
            "ğŸ¤– ì•ˆë…•í•˜ì„¸ìš”! í˜„ì¬ AI ê¸°ëŠ¥ì´ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.",
            "âš™ï¸ OpenAI API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. Week 2ì—ì„œ AI ì—°ë™ì„ ì™„ë£Œí•  ì˜ˆì •ì…ë‹ˆë‹¤.",
            "ğŸ”§ AI ì±„íŒ… ê¸°ëŠ¥ì„ êµ¬í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê³§ ì‹¤ì œ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤!",
            "ğŸ“ í˜„ì¬ëŠ” ë°ëª¨ ëª¨ë“œì…ë‹ˆë‹¤. ì‹¤ì œ AI ë¶„ì„ ê¸°ëŠ¥ì€ ë‹¨ê³„ì ìœ¼ë¡œ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤."
        ]
        
        # ë©”ì‹œì§€ ë‚´ìš©ì— ë”°ë¥¸ ë§ì¶¤ ì‘ë‹µ
        message_lower = user_message.lower()
        
        if any(keyword in message_lower for keyword in ['ë§¤ì¶œ', 'ë¶„ì„', 'ë°ì´í„°']):
            return "ğŸ“Š ë°ì´í„° ë¶„ì„ ê´€ë ¨ ì§ˆë¬¸ì´ì‹œë„¤ìš”! Week 3-5ì—ì„œ ì‹¤ì œ ë¶„ì„ ê¸°ëŠ¥ì´ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤. í˜„ì¬ëŠ” AI ì±„íŒ… ê¸°ë³¸ ê¸°ëŠ¥ì„ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤."
        
        elif any(keyword in message_lower for keyword in ['sql', 'ì¿¼ë¦¬', 'ë°ì´í„°ë² ì´ìŠ¤']):
            return "ğŸ—„ï¸ SQL ë°ì´í„°ë² ì´ìŠ¤ ê¸°ëŠ¥ì€ Week 3ì—ì„œ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤. LangChain SQLDatabaseChainì„ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ê°œë°œí•  ê³„íšì…ë‹ˆë‹¤."
        
        elif any(keyword in message_lower for keyword in ['íŒŒì¼', 'excel', 'csv']):
            return "ğŸ“ Excel/CSV íŒŒì¼ ë¶„ì„ ê¸°ëŠ¥ì€ Week 4ì—ì„œ êµ¬í˜„ë  ì˜ˆì •ì…ë‹ˆë‹¤. Pandasë¥¼ í™œìš©í•œ ìë™ ë¶„ì„ ê¸°ëŠ¥ì„ ê°œë°œí•  ê³„íšì…ë‹ˆë‹¤."
        
        else:
            import random
            return random.choice(responses)
    
    def _get_error_response(self, error: str) -> str:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        return f"âŒ ì£„ì†¡í•©ë‹ˆë‹¤. AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ”§ **ì˜¤ë¥˜ ì •ë³´**: {error}\n\nğŸ’¡ **í•´ê²° ë°©ë²•**: OpenAI API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.langchain_manager:
            self.langchain_manager.clear_memory()
        self.conversation_count = 0
        logger.info("ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        if not self.langchain_manager:
            return []
        
        history = []
        messages = self.langchain_manager.get_conversation_history()
        
        for i in range(0, len(messages) - 1, 2):
            if i + 1 < len(messages):
                user_msg = messages[i]
                ai_msg = messages[i + 1]
                
                history.append({
                    "user_message": user_msg.content,
                    "ai_response": ai_msg.content,
                    "timestamp": datetime.now().isoformat()
                })
        
        return history
    
    def test_ai_connection(self) -> Tuple[bool, str]:
        """AI ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.is_available:
            return False, "AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
        
        try:
            # OpenAI ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•œ ë” ì •í™•í•œ í…ŒìŠ¤íŠ¸
            success, message = validator.test_api_connection(
                settings.openai_api_key,
                settings.openai_model
            )
            
            if success:
                logger.info("AI ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True, f"âœ… {message}"
            else:
                logger.warning("AI ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨", reason=message)
                return False, f"âŒ {message}"
                
        except Exception as e:
            logger.error("AI ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜", error=str(e))
            return False, f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}"


# ì „ì—­ AI ì±„íŒ… ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
ai_chat_service = AIChatService()
