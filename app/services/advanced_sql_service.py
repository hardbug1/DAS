"""
ê³ ê¸‰ SQL ìƒì„± ì„œë¹„ìŠ¤

ë³µì¡í•œ ì¿¼ë¦¬ ì§€ì›, ìŠ¤í‚¤ë§ˆ ì¸ì‹ ê°•í™”, ìì—°ì–´ ì´í•´ í–¥ìƒì„ ìœ„í•œ ê³ ê¸‰ SQL ìƒì„± ì—”ì§„
"""

import re
import structlog
from typing import Dict, List, Any, Tuple, Optional
from datetime import datetime, timedelta
try:
    from dateutil import parser as date_parser
except ImportError:
    date_parser = None
from sqlalchemy import text, inspect
from app.config.database import engine, SessionLocal
from app.core.database_schema import Base

logger = structlog.get_logger()


class NaturalLanguageProcessor:
    """ìì—°ì–´ ì²˜ë¦¬ ë° SQL ë§¤í•‘"""
    
    def __init__(self):
        self.time_patterns = self._initialize_time_patterns()
        self.business_terms = self._initialize_business_terms()
        self.aggregation_terms = self._initialize_aggregation_terms()
        
    def _initialize_time_patterns(self) -> Dict[str, str]:
        """ì‹œê°„ í‘œí˜„ íŒ¨í„´ ì •ì˜"""
        return {
            # ìƒëŒ€ì  ì‹œê°„
            r'ì§€ë‚œ\s*(\d+)\s*ë…„': lambda m: f"sale_date >= DATE('{datetime.now() - timedelta(days=int(m.group(1))*365)}')",
            r'ì§€ë‚œ\s*(\d+)\s*ë‹¬|ì§€ë‚œ\s*(\d+)\s*ê°œì›”': lambda m: f"sale_date >= DATE('{datetime.now() - timedelta(days=int(m.group(1) or m.group(2))*30)}')",
            r'ì§€ë‚œ\s*(\d+)\s*ì£¼': lambda m: f"sale_date >= DATE('{datetime.now() - timedelta(weeks=int(m.group(1)))}')",
            r'ì§€ë‚œ\s*(\d+)\s*ì¼': lambda m: f"sale_date >= DATE('{datetime.now() - timedelta(days=int(m.group(1)))}')",
            
            # íŠ¹ì • ê¸°ê°„
            r'ì˜¬í•´|ê¸ˆë…„': f"EXTRACT(YEAR FROM sale_date) = {datetime.now().year}",
            r'ì‘ë…„|ì§€ë‚œí•´': f"EXTRACT(YEAR FROM sale_date) = {datetime.now().year - 1}",
            r'ì´ë²ˆ\s*ë‹¬|ì´ë²ˆ\s*ì›”': f"EXTRACT(YEAR FROM sale_date) = {datetime.now().year} AND EXTRACT(MONTH FROM sale_date) = {datetime.now().month}",
            r'ì§€ë‚œ\s*ë‹¬|ì €ë²ˆ\s*ë‹¬': f"EXTRACT(YEAR FROM sale_date) = {datetime.now().year} AND EXTRACT(MONTH FROM sale_date) = {datetime.now().month - 1 if datetime.now().month > 1 else 12}",
            
            # ê³„ì ˆ
            r'ë´„': "EXTRACT(MONTH FROM sale_date) IN (3, 4, 5)",
            r'ì—¬ë¦„': "EXTRACT(MONTH FROM sale_date) IN (6, 7, 8)",
            r'ê°€ì„': "EXTRACT(MONTH FROM sale_date) IN (9, 10, 11)",
            r'ê²¨ìš¸': "EXTRACT(MONTH FROM sale_date) IN (12, 1, 2)",
            
            # ìš”ì¼
            r'í‰ì¼': "EXTRACT(DOW FROM sale_date) BETWEEN 1 AND 5",
            r'ì£¼ë§': "EXTRACT(DOW FROM sale_date) IN (0, 6)",
        }
    
    def _initialize_business_terms(self) -> Dict[str, Dict[str, str]]:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ ë§¤í•‘"""
        return {
            # ë§¤ì¶œ ê´€ë ¨
            'revenue': {
                'patterns': [r'ë§¤ì¶œ', r'ìˆ˜ìµ', r'ë§¤ì¶œì•¡', r'ìˆ˜ì…', r'íŒë§¤ì•¡'],
                'column': 'sales.amount',
                'table': 'sales',
                'aggregation': 'SUM'
            },
            'profit': {
                'patterns': [r'ìˆ˜ìµ', r'ì´ìµ', r'ìˆœì´ìµ'],
                'column': 'sales.amount - (order_items.quantity * products.price * 0.7)',  # ê°€ì •ì  ì›ê°€ìœ¨
                'table': 'sales',
                'aggregation': 'SUM'
            },
            
            # ê³ ê° ê´€ë ¨
            'customer_count': {
                'patterns': [r'ê³ ê°\s*ìˆ˜', r'ê³ ê°\s*ìˆ«ì', r'íšŒì›\s*ìˆ˜'],
                'column': 'customers.id',
                'table': 'customers',
                'aggregation': 'COUNT(DISTINCT'
            },
            'customer_age': {
                'patterns': [r'ê³ ê°\s*ë‚˜ì´', r'ì—°ë ¹', r'ë‚˜ì´'],
                'column': 'customers.age',
                'table': 'customers',
                'aggregation': 'AVG'
            },
            
            # ì œí’ˆ ê´€ë ¨
            'product_count': {
                'patterns': [r'ì œí’ˆ\s*ìˆ˜', r'ìƒí’ˆ\s*ìˆ˜', r'ì•„ì´í…œ\s*ìˆ˜'],
                'column': 'products.id',
                'table': 'products',
                'aggregation': 'COUNT'
            },
            'inventory': {
                'patterns': [r'ì¬ê³ ', r'ì¬ê³ ëŸ‰', r'ë³´ìœ ëŸ‰'],
                'column': 'products.stock_quantity',
                'table': 'products',
                'aggregation': 'SUM'
            },
            
            # ì£¼ë¬¸ ê´€ë ¨
            'order_count': {
                'patterns': [r'ì£¼ë¬¸\s*ìˆ˜', r'ì£¼ë¬¸\s*ê±´ìˆ˜', r'ê±°ë˜\s*ê±´ìˆ˜'],
                'column': 'orders.id',
                'table': 'orders',
                'aggregation': 'COUNT'
            },
            'order_amount': {
                'patterns': [r'ì£¼ë¬¸\s*ê¸ˆì•¡', r'ê±°ë˜\s*ê¸ˆì•¡', r'ì£¼ë¬¸ì•¡'],
                'column': 'orders.total_amount',
                'table': 'orders',
                'aggregation': 'AVG'
            }
        }
    
    def _initialize_aggregation_terms(self) -> Dict[str, str]:
        """ì§‘ê³„ í•¨ìˆ˜ ë§¤í•‘"""
        return {
            r'ì´|ì „ì²´|í•©ê³„': 'SUM',
            r'í‰ê· |avg': 'AVG',
            r'ìµœëŒ€|ìµœê³ |max': 'MAX',
            r'ìµœì†Œ|ìµœì €|min': 'MIN',
            r'ê°œìˆ˜|ìˆ˜ëŸ‰|ê±´ìˆ˜|count': 'COUNT',
            r'ìƒìœ„|top': 'ORDER BY {column} DESC LIMIT',
            r'í•˜ìœ„|bottom': 'ORDER BY {column} ASC LIMIT',
        }
    
    def parse_natural_language(self, question: str) -> Dict[str, Any]:
        """ìì—°ì–´ ì§ˆë¬¸ì„ êµ¬ì¡°í™”ëœ ì •ë³´ë¡œ íŒŒì‹±"""
        parsed = {
            'intent': self._detect_intent(question),
            'entities': self._extract_entities(question),
            'time_conditions': self._extract_time_conditions(question),
            'aggregations': self._extract_aggregations(question),
            'filters': self._extract_filters(question),
            'sorting': self._extract_sorting(question),
            'grouping': self._extract_grouping(question)
        }
        
        logger.info("ìì—°ì–´ íŒŒì‹± ì™„ë£Œ", question=question, parsed=parsed)
        return parsed
    
    def _detect_intent(self, question: str) -> str:
        """ì§ˆë¬¸ì˜ ì˜ë„ ê°ì§€"""
        question_lower = question.lower()
        
        if any(pattern in question_lower for pattern in ['ë¹„êµ', 'ì°¨ì´', 'ëŒ€ë¹„']):
            return 'comparison'
        elif any(pattern in question_lower for pattern in ['ì¶”ì„¸', 'íŠ¸ë Œë“œ', 'ë³€í™”', 'ì¦ê°€', 'ê°ì†Œ']):
            return 'trend'
        elif any(pattern in question_lower for pattern in ['ìƒìœ„', 'top', 'ìµœê³ ', 'ê°€ì¥ ë§ì´']):
            return 'ranking'
        elif any(pattern in question_lower for pattern in ['ë¶„í¬', 'ë¶„ì„', 'í†µê³„']):
            return 'distribution'
        elif any(pattern in question_lower for pattern in ['ì´', 'í•©ê³„', 'ì „ì²´']):
            return 'aggregation'
        else:
            return 'general'
    
    def _extract_entities(self, question: str) -> List[Dict[str, str]]:
        """ì—”í‹°í‹° ì¶”ì¶œ (í…Œì´ë¸”, ì»¬ëŸ¼, ê°’)"""
        entities = []
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´ ë§¤ì¹­
        for term, info in self.business_terms.items():
            for pattern in info['patterns']:
                if re.search(pattern, question):
                    entities.append({
                        'type': 'business_term',
                        'value': term,
                        'column': info['column'],
                        'table': info['table'],
                        'aggregation': info['aggregation']
                    })
        
        # ì§€ì—­ ë§¤ì¹­
        regions = ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ìˆ˜ì›', 'ì°½ì›', 'ì„±ë‚¨']
        for region in regions:
            if region in question:
                entities.append({
                    'type': 'location',
                    'value': region,
                    'column': 'customers.city',
                    'condition': f"customers.city = '{region}'"
                })
        
        # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
        categories = ['ì „ìì œí’ˆ', 'ì˜ë¥˜', 'ì‹í’ˆ', 'ìƒí™œìš©í’ˆ', 'í™”ì¥í’ˆ']
        for category in categories:
            if category in question:
                entities.append({
                    'type': 'category',
                    'value': category,
                    'column': 'products.category',
                    'condition': f"products.category = '{category}'"
                })
        
        return entities
    
    def _extract_time_conditions(self, question: str) -> List[str]:
        """ì‹œê°„ ì¡°ê±´ ì¶”ì¶œ"""
        conditions = []
        
        for pattern, condition in self.time_patterns.items():
            matches = re.finditer(pattern, question)
            for match in matches:
                if callable(condition):
                    conditions.append(condition(match))
                else:
                    conditions.append(condition)
        
        return conditions
    
    def _extract_aggregations(self, question: str) -> List[Dict[str, str]]:
        """ì§‘ê³„ í•¨ìˆ˜ ì¶”ì¶œ"""
        aggregations = []
        
        for pattern, func in self.aggregation_terms.items():
            if re.search(pattern, question):
                aggregations.append({
                    'function': func,
                    'pattern': pattern
                })
        
        return aggregations
    
    def _extract_filters(self, question: str) -> List[str]:
        """í•„í„° ì¡°ê±´ ì¶”ì¶œ"""
        filters = []
        
        # ìˆ«ì ë²”ìœ„ íŒ¨í„´
        amount_patterns = [
            (r'(\d+)ë§Œì›\s*ì´ìƒ', lambda m: f"total_amount >= {int(m.group(1)) * 10000}"),
            (r'(\d+)ë§Œì›\s*ì´í•˜', lambda m: f"total_amount <= {int(m.group(1)) * 10000}"),
            (r'(\d+)\s*ì„¸\s*ì´ìƒ', lambda m: f"customers.age >= {m.group(1)}"),
            (r'(\d+)\s*ì„¸\s*ì´í•˜', lambda m: f"customers.age <= {m.group(1)}"),
        ]
        
        for pattern, converter in amount_patterns:
            matches = re.finditer(pattern, question)
            for match in matches:
                filters.append(converter(match))
        
        return filters
    
    def _extract_sorting(self, question: str) -> Optional[Dict[str, str]]:
        """ì •ë ¬ ì¡°ê±´ ì¶”ì¶œ"""
        if re.search(r'ë†’ì€\s*ìˆœ|ë§ì€\s*ìˆœ|í°\s*ìˆœ', question):
            return {'direction': 'DESC'}
        elif re.search(r'ë‚®ì€\s*ìˆœ|ì ì€\s*ìˆœ|ì‘ì€\s*ìˆœ', question):
            return {'direction': 'ASC'}
        
        return None
    
    def _extract_grouping(self, question: str) -> List[str]:
        """ê·¸ë£¹í™” ì¡°ê±´ ì¶”ì¶œ"""
        grouping = []
        
        group_patterns = {
            r'ì§€ì—­ë³„|ë„ì‹œë³„': 'customers.city',
            r'ì¹´í…Œê³ ë¦¬ë³„|ë¶„ë¥˜ë³„': 'products.category',
            r'ì›”ë³„|ë‹¬ë³„': 'EXTRACT(MONTH FROM sale_date)',
            r'ë…„ë„ë³„|ì—°ë„ë³„': 'EXTRACT(YEAR FROM sale_date)',
            r'ìš”ì¼ë³„': 'EXTRACT(DOW FROM sale_date)',
            r'ê³ ê°ë³„': 'customers.id',
            r'ì œí’ˆë³„|ìƒí’ˆë³„': 'products.id',
            r'íšŒì‚¬ë³„|ì—…ì²´ë³„': 'companies.name'
        }
        
        for pattern, column in group_patterns.items():
            if re.search(pattern, question):
                grouping.append(column)
        
        return grouping


class QueryOptimizer:
    """SQL ì¿¼ë¦¬ ìµœì í™”"""
    
    def __init__(self):
        self.optimization_rules = self._initialize_optimization_rules()
    
    def _initialize_optimization_rules(self) -> List[Dict[str, Any]]:
        """ìµœì í™” ê·œì¹™ ì •ì˜"""
        return [
            {
                'name': 'index_hint',
                'pattern': r'WHERE.*customers\.city',
                'suggestion': 'customers.city ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ìƒì„±ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.',
                'optimization': 'CREATE INDEX idx_customers_city ON customers(city);'
            },
            {
                'name': 'join_optimization',
                'pattern': r'JOIN.*JOIN.*JOIN',
                'suggestion': 'ë‹¤ì¤‘ JOIN ì¿¼ë¦¬ì…ë‹ˆë‹¤. í•„ìš”í•œ ì»¬ëŸ¼ë§Œ SELECTí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
                'optimization': None
            },
            {
                'name': 'limit_suggestion',
                'pattern': r'ORDER BY.*(?!LIMIT)',
                'suggestion': 'ì •ë ¬ ì¿¼ë¦¬ì— LIMITë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ í–¥ìƒë©ë‹ˆë‹¤.',
                'optimization': None
            }
        ]
    
    def optimize_query(self, sql_query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ìµœì í™” ë° ì œì•ˆì‚¬í•­ ë°˜í™˜"""
        suggestions = []
        optimizations = []
        
        for rule in self.optimization_rules:
            if re.search(rule['pattern'], sql_query, re.IGNORECASE):
                suggestions.append(rule['suggestion'])
                if rule['optimization']:
                    optimizations.append(rule['optimization'])
        
        # ê¸°ë³¸ ì„±ëŠ¥ ë¶„ì„
        performance_analysis = self._analyze_performance(sql_query)
        
        return {
            'suggestions': suggestions,
            'optimizations': optimizations,
            'performance_analysis': performance_analysis,
            'complexity_score': self._calculate_complexity(sql_query)
        }
    
    def _analyze_performance(self, sql_query: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„"""
        analysis = {
            'estimated_complexity': 'medium',
            'join_count': len(re.findall(r'\bJOIN\b', sql_query, re.IGNORECASE)),
            'subquery_count': len(re.findall(r'\bSELECT\b.*\bFROM\b.*\bSELECT\b', sql_query, re.IGNORECASE)),
            'aggregation_count': len(re.findall(r'\b(SUM|AVG|COUNT|MAX|MIN)\b', sql_query, re.IGNORECASE))
        }
        
        # ë³µì¡ë„ ê³„ì‚°
        complexity_score = (
            analysis['join_count'] * 2 +
            analysis['subquery_count'] * 3 +
            analysis['aggregation_count'] * 1
        )
        
        if complexity_score <= 3:
            analysis['estimated_complexity'] = 'low'
        elif complexity_score <= 8:
            analysis['estimated_complexity'] = 'medium'
        else:
            analysis['estimated_complexity'] = 'high'
        
        return analysis
    
    def _calculate_complexity(self, sql_query: str) -> int:
        """ì¿¼ë¦¬ ë³µì¡ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        
        # ê¸°ë³¸ ì ìˆ˜
        score += 1
        
        # JOIN ì ìˆ˜
        score += len(re.findall(r'\bJOIN\b', sql_query, re.IGNORECASE)) * 2
        
        # ì„œë¸Œì¿¼ë¦¬ ì ìˆ˜
        score += len(re.findall(r'\(\s*SELECT\b', sql_query, re.IGNORECASE)) * 3
        
        # ì§‘ê³„ í•¨ìˆ˜ ì ìˆ˜
        score += len(re.findall(r'\b(SUM|AVG|COUNT|MAX|MIN)\b', sql_query, re.IGNORECASE))
        
        # GROUP BY ì ìˆ˜
        if re.search(r'\bGROUP BY\b', sql_query, re.IGNORECASE):
            score += 2
        
        # ORDER BY ì ìˆ˜
        if re.search(r'\bORDER BY\b', sql_query, re.IGNORECASE):
            score += 1
        
        return score


class AdvancedSQLService:
    """ê³ ê¸‰ SQL ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.nlp = NaturalLanguageProcessor()
        self.optimizer = QueryOptimizer()
        self.schema_info = self._load_schema_info()
        
    def _load_schema_info(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ ë¡œë“œ"""
        try:
            inspector = inspect(engine)
            tables = inspector.get_table_names()
            
            schema_info = {}
            for table_name in tables:
                columns = inspector.get_columns(table_name)
                foreign_keys = inspector.get_foreign_keys(table_name)
                indexes = inspector.get_indexes(table_name)
                
                schema_info[table_name] = {
                    'columns': {col['name']: col['type'] for col in columns},
                    'foreign_keys': foreign_keys,
                    'indexes': indexes
                }
            
            logger.info("ìŠ¤í‚¤ë§ˆ ì •ë³´ ë¡œë“œ ì™„ë£Œ", tables_count=len(tables))
            return schema_info
            
        except Exception as e:
            logger.error("ìŠ¤í‚¤ë§ˆ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨", error=str(e))
            return {}
    
    def generate_advanced_sql(self, question: str) -> Dict[str, Any]:
        """ê³ ê¸‰ SQL ì¿¼ë¦¬ ìƒì„±"""
        try:
            # ìì—°ì–´ íŒŒì‹±
            parsed = self.nlp.parse_natural_language(question)
            
            # SQL êµ¬ì„± ìš”ì†Œ ìƒì„±
            sql_components = self._build_sql_components(parsed)
            
            # SQL ì¿¼ë¦¬ ì¡°ë¦½
            sql_query = self._assemble_sql_query(sql_components)
            
            # ì¿¼ë¦¬ ìµœì í™” ë° ë¶„ì„
            optimization = self.optimizer.optimize_query(sql_query)
            
            # ì„¤ëª… ìƒì„±
            explanation = self._generate_explanation(parsed, sql_components, optimization)
            
            return {
                'success': True,
                'sql_query': sql_query,
                'parsed_intent': parsed,
                'optimization': optimization,
                'explanation': explanation,
                'complexity_score': optimization['complexity_score']
            }
            
        except Exception as e:
            logger.error("ê³ ê¸‰ SQL ìƒì„± ì‹¤íŒ¨", error=str(e))
            return {
                'success': False,
                'error': str(e),
                'sql_query': None,
                'explanation': f"SQL ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
    
    def _build_sql_components(self, parsed: Dict[str, Any]) -> Dict[str, Any]:
        """SQL êµ¬ì„± ìš”ì†Œ ë¹Œë“œ"""
        components = {
            'select': self._build_select_clause(parsed),
            'from': self._build_from_clause(parsed),
            'joins': self._build_joins(parsed),
            'where': self._build_where_clause(parsed),
            'group_by': self._build_group_by(parsed),
            'having': self._build_having_clause(parsed),
            'order_by': self._build_order_by(parsed),
            'limit': self._build_limit_clause(parsed)
        }
        
        return components
    
    def _build_select_clause(self, parsed: Dict[str, Any]) -> str:
        """SELECT ì ˆ êµ¬ì„±"""
        select_columns = []
        
        # ì—”í‹°í‹° ê¸°ë°˜ ì»¬ëŸ¼ ì„ íƒ
        for entity in parsed['entities']:
            if entity['type'] == 'business_term':
                if 'COUNT' in entity['aggregation']:
                    select_columns.append(f"{entity['aggregation']}({entity['column']}))")
                else:
                    select_columns.append(f"{entity['aggregation']}({entity['column']})")
        
        # ê·¸ë£¹í™” ì»¬ëŸ¼ ì¶”ê°€
        for group_col in parsed['grouping']:
            if group_col not in select_columns:
                select_columns.append(group_col)
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        if not select_columns:
            select_columns = ['*']
        
        return ', '.join(select_columns)
    
    def _build_from_clause(self, parsed: Dict[str, Any]) -> str:
        """FROM ì ˆ êµ¬ì„±"""
        # ì£¼ìš” í…Œì´ë¸” ê²°ì •
        main_tables = set()
        for entity in parsed['entities']:
            if 'table' in entity:
                main_tables.add(entity['table'])
        
        if not main_tables:
            return 'sales'  # ê¸°ë³¸ í…Œì´ë¸”
        
        return list(main_tables)[0]  # ì²« ë²ˆì§¸ í…Œì´ë¸”ì„ ë©”ì¸ìœ¼ë¡œ
    
    def _build_joins(self, parsed: Dict[str, Any]) -> List[str]:
        """JOIN ì ˆ êµ¬ì„±"""
        joins = []
        
        # í•„ìš”í•œ í…Œì´ë¸”ë“¤ ìˆ˜ì§‘
        required_tables = set()
        for entity in parsed['entities']:
            if 'table' in entity:
                required_tables.add(entity['table'])
        
        # í‘œì¤€ JOIN íŒ¨í„´
        join_patterns = [
            ("sales", "orders", "sales.order_id = orders.id"),
            ("orders", "customers", "orders.customer_id = customers.id"),
            ("orders", "order_items", "orders.id = order_items.order_id"),
            ("order_items", "products", "order_items.product_id = products.id"),
            ("products", "companies", "products.company_id = companies.id")
        ]
        
        for table1, table2, condition in join_patterns:
            if table1 in required_tables and table2 in required_tables:
                joins.append(f"JOIN {table2} ON {condition}")
        
        return joins
    
    def _build_where_clause(self, parsed: Dict[str, Any]) -> List[str]:
        """WHERE ì ˆ êµ¬ì„±"""
        conditions = []
        
        # ì‹œê°„ ì¡°ê±´
        conditions.extend(parsed['time_conditions'])
        
        # í•„í„° ì¡°ê±´
        conditions.extend(parsed['filters'])
        
        # ì—”í‹°í‹° ì¡°ê±´
        for entity in parsed['entities']:
            if 'condition' in entity:
                conditions.append(entity['condition'])
        
        return conditions
    
    def _build_group_by(self, parsed: Dict[str, Any]) -> List[str]:
        """GROUP BY ì ˆ êµ¬ì„±"""
        return parsed['grouping']
    
    def _build_having_clause(self, parsed: Dict[str, Any]) -> List[str]:
        """HAVING ì ˆ êµ¬ì„±"""
        # ì§‘ê³„ í•¨ìˆ˜ì— ëŒ€í•œ ì¡°ê±´
        having = []
        
        # ì˜ˆ: "í‰ê·  ì£¼ë¬¸ì•¡ì´ 10ë§Œì› ì´ìƒì¸"
        for entity in parsed['entities']:
            if entity['type'] == 'business_term' and 'aggregation' in entity:
                # ì¶”í›„ êµ¬í˜„ ì˜ˆì •
                pass
        
        return having
    
    def _build_order_by(self, parsed: Dict[str, Any]) -> Optional[str]:
        """ORDER BY ì ˆ êµ¬ì„±"""
        sorting = parsed['sorting']
        if not sorting:
            return None
        
        # ì •ë ¬ ëŒ€ìƒ ê²°ì •
        sort_column = None
        for entity in parsed['entities']:
            if entity['type'] == 'business_term':
                if 'aggregation' in entity:
                    sort_column = f"{entity['aggregation']}({entity['column']})"
                else:
                    sort_column = entity['column']
                break
        
        if not sort_column:
            sort_column = "1"  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
        
        return f"{sort_column} {sorting['direction']}"
    
    def _build_limit_clause(self, parsed: Dict[str, Any]) -> Optional[int]:
        """LIMIT ì ˆ êµ¬ì„±"""
        # TOP N íŒ¨í„´ ê²€ìƒ‰
        for agg in parsed['aggregations']:
            if 'LIMIT' in agg['function']:
                # ìˆ«ì ì¶”ì¶œ (ì˜ˆ: "ìƒìœ„ 5ê°œ")
                return 5  # ê¸°ë³¸ê°’
        
        return None
    
    def _assemble_sql_query(self, components: Dict[str, Any]) -> str:
        """SQL ì¿¼ë¦¬ ì¡°ë¦½"""
        query_parts = []
        
        # SELECT
        query_parts.append(f"SELECT {components['select']}")
        
        # FROM
        query_parts.append(f"FROM {components['from']}")
        
        # JOINs
        for join in components['joins']:
            query_parts.append(join)
        
        # WHERE
        if components['where']:
            query_parts.append(f"WHERE {' AND '.join(components['where'])}")
        
        # GROUP BY
        if components['group_by']:
            query_parts.append(f"GROUP BY {', '.join(components['group_by'])}")
        
        # HAVING
        if components['having']:
            query_parts.append(f"HAVING {' AND '.join(components['having'])}")
        
        # ORDER BY
        if components['order_by']:
            query_parts.append(f"ORDER BY {components['order_by']}")
        
        # LIMIT
        if components['limit']:
            query_parts.append(f"LIMIT {components['limit']}")
        
        return '\n'.join(query_parts)
    
    def _generate_explanation(self, parsed: Dict[str, Any], components: Dict[str, Any], optimization: Dict[str, Any]) -> str:
        """ì¿¼ë¦¬ ì„¤ëª… ìƒì„±"""
        explanation_parts = []
        
        explanation_parts.append("ğŸ” **ì¿¼ë¦¬ ë¶„ì„ ê²°ê³¼:**")
        
        # ì˜ë„ ì„¤ëª…
        intent_descriptions = {
            'comparison': 'ë°ì´í„° ë¹„êµ ë¶„ì„',
            'trend': 'íŠ¸ë Œë“œ ë¶„ì„',
            'ranking': 'ìˆœìœ„ ë¶„ì„',
            'distribution': 'ë¶„í¬ ë¶„ì„',
            'aggregation': 'ì§‘ê³„ ë¶„ì„',
            'general': 'ì¼ë°˜ ì¡°íšŒ'
        }
        explanation_parts.append(f"- **ë¶„ì„ ìœ í˜•**: {intent_descriptions.get(parsed['intent'], 'ì¼ë°˜ ì¡°íšŒ')}")
        
        # ëŒ€ìƒ í…Œì´ë¸”
        tables = set()
        for entity in parsed['entities']:
            if 'table' in entity:
                tables.add(entity['table'])
        if tables:
            explanation_parts.append(f"- **ëŒ€ìƒ í…Œì´ë¸”**: {', '.join(tables)}")
        
        # ì‹œê°„ ì¡°ê±´
        if parsed['time_conditions']:
            explanation_parts.append(f"- **ì‹œê°„ ì¡°ê±´**: {len(parsed['time_conditions'])}ê°œ ì ìš©")
        
        # ê·¸ë£¹í™”
        if parsed['grouping']:
            explanation_parts.append(f"- **ê·¸ë£¹í™”**: {', '.join(parsed['grouping'])}")
        
        # ì„±ëŠ¥ ì •ë³´
        complexity = optimization['performance_analysis']['estimated_complexity']
        complexity_desc = {'low': 'ë‚®ìŒ', 'medium': 'ë³´í†µ', 'high': 'ë†’ìŒ'}
        explanation_parts.append(f"- **ì¿¼ë¦¬ ë³µì¡ë„**: {complexity_desc.get(complexity, 'ë³´í†µ')} (ì ìˆ˜: {optimization['complexity_score']})")
        
        # ìµœì í™” ì œì•ˆ
        if optimization['suggestions']:
            explanation_parts.append("\nğŸ’¡ **ìµœì í™” ì œì•ˆ:**")
            for suggestion in optimization['suggestions']:
                explanation_parts.append(f"- {suggestion}")
        
        return '\n'.join(explanation_parts)


# ì „ì—­ ê³ ê¸‰ SQL ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
advanced_sql_service = AdvancedSQLService()
